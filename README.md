# **Project: StreamSync**

**Description:**  
StreamSync is a real-time data streaming platform using **React (Next.js) for the frontend**, **Node.js for the backend**, and **Kafka as a message broker**. It extracts, transforms, and loads (ETL) time-series data into a database and streams live updates to the UI using WebSockets.

---

## **Table of Contents**

1. [Project Overview](#project-overview)
2. [Tech Stack](#tech-stack)
3. [Project File Structure](#project-file-structure)
4. [Setup and Installation](#setup-and-installation)
5. [Backend Implementation](#backend-implementation)
6. [Frontend Implementation](#frontend-implementation)
7. [Kafka Integration](#kafka-integration)
8. [WebSocket Streaming](#websocket-streaming)
9. [Deployment](#deployment)
10. [Future Enhancements](#future-enhancements)

---

## **1. Project Overview**

StreamSync processes real-time data through an **ETL pipeline**, using Kafka to decouple services. The system ensures that different components (data sources, processing units, UI) interact without dependencies, making it scalable and resilient.

### **Key Features:**

- **Real-time data streaming** to UI via WebSockets
- **Kafka-based message brokering** for decoupling services
- **ETL pipeline** to process and store structured data
- **React + Next.js frontend** with live updates
- **Node.js + Express backend** for API handling

---

## **2. Tech Stack**

### **Frontend (Client-Side)**

- **React.js (Next.js)** – Server-side rendering and static site generation
- **WebSockets** – Live data subscriptions
- **Tailwind CSS** – Styling

### **Backend (Server-Side)**

- **Node.js + Express** – REST API & WebSocket server
- **Kafka** – Message broker for real-time processing
- **PostgreSQL (or AWS DynamoDB)** – Database storage

### **Infrastructure**

- **AWS (EC2, S3, Lambda)** – Cloud hosting
- **Docker** – Containerized deployment
- **Hasura** – Auto-generating GraphQL APIs (optional)

---

## **3. Project File Structure**

```
StreamSync/                          # Root directory of the project
│── backend/                         # Folder - Node.js Backend
│   ├── src/                         # Folder - Source code for the backend
│   │   ├── controllers/             # Folder - API Controllers
│   │   ├── kafka/                   # Folder - Kafka Producers & Consumers
│   │   ├── models/                  # Folder - Database Models (PostgreSQL)
│   │   ├── routes/                  # Folder - API Routes
│   │   ├── server.js                # File - Express Server (JavaScript)
│   │   ├── websocket.js             # File - WebSocket Server (JavaScript)
│   ├── .env                         # File - Environment Variables
│   ├── package.json                 # File - Backend Dependencies (JSON)
│── frontend/                        # Folder - Next.js Frontend
│   ├── pages/                       # Folder - Next.js Pages
│   │   ├── index.js                 # File - Home Page (JavaScript)
│   │   ├── dashboard.js             # File - Example Dashboard Page (JavaScript)
│   │   ├── api/                     # Folder - API Routes for Next.js
│   ├── components/                  # Folder - Reusable UI Components
│   │   ├── Header.js                # File - Navigation Bar Component (JavaScript)
│   │   ├── Footer.js                # File - Footer Component (JavaScript)
│   ├── hooks/                       # Folder - Custom React Hooks
│   │   ├── useAuth.js               # File - Example Custom Hook for Authentication (JavaScript)
│   ├── styles/                      # Folder - Styling
│   │   ├── global.css               # File - Global CSS Styles
│   │   ├── theme.module.css         # File - Module CSS for Theming
│   ├── public/                      # Folder - Static Assets
│   │   ├── logo.png                 # File - Logo Image (PNG)
│   ├── package.json                 # File - Frontend Dependencies (JSON)
│── database/                        # Folder - Database Scripts
│   ├── schema.sql                   # File - Database Schema (SQL)
│   ├── seed.sql                     # File - Sample Data for Testing (SQL)
│── docker-compose.yml               # File - Docker Configuration (YAML)
│── .gitignore                       # File - Ignore Node Modules, Logs, etc. (Text)
│── LICENSE                          # File - MIT License (Text)
│── README.md                        # File - Documentation (Markdown)

```

---

## **4. Setup and Installation**

### **Prerequisites**

- Install **Node.js (v18+)**
- Install **Kafka** (via Docker or local setup)
- Install **PostgreSQL**

### **Backend Setup**

```bash
cd backend
npm install
cp .env.example .env  # Set up environment variables
node src/server.js
```

### **Frontend Setup**

```bash
cd frontend
npm install
npm run dev
```

### **Running Kafka (Using Docker)**

```bash
docker-compose up
```

---

## **5. Backend Implementation**

### **server.js (Express Backend)**

```javascript
const express = require("express");
const cors = require("cors");
const { setupKafka } = require("./kafka/kafkaConfig");

const app = express();
app.use(cors());
app.use(express.json());

const PORT = process.env.PORT || 5000;

// Kafka setup
setupKafka();

app.get("/", (req, res) => {
  res.send("Backend is running...");
});

app.listen(PORT, () => {
  console.log(`Server running on port ${PORT}`);
});
```

### **WebSocket Streaming**

```javascript
const WebSocket = require("ws");

const wss = new WebSocket.Server({ port: 8080 });

wss.on("connection", (ws) => {
  console.log("New WebSocket connection");
  ws.send(JSON.stringify({ message: "Connected to WebSocket" }));
});
```

---

## **6. Frontend Implementation**

### **Using WebSockets in React**

```javascript
import { useEffect, useState } from "react";

export default function LiveData() {
  const [data, setData] = useState(null);

  useEffect(() => {
    const ws = new WebSocket("ws://localhost:8080");

    ws.onmessage = (event) => {
      const newData = JSON.parse(event.data);
      setData(newData);
    };

    return () => ws.close();
  }, []);

  return (
    <div>
      Live Data: {data ? JSON.stringify(data) : "Waiting for updates..."}
    </div>
  );
}
```

---

## **7. Kafka Integration**

### **Producer (Sending Messages)**

```javascript
const { Kafka } = require("kafkajs");

const kafka = new Kafka({
  clientId: "streamsync",
  brokers: ["localhost:9092"],
});

const producer = kafka.producer();

async function sendMessage(data) {
  await producer.connect();
  await producer.send({
    topic: "stream_topic",
    messages: [{ value: JSON.stringify(data) }],
  });
  await producer.disconnect();
}

module.exports = { sendMessage };
```

### **Consumer (Receiving Messages)**

```javascript
const consumer = kafka.consumer({ groupId: "streamsync-group" });

async function startConsumer() {
  await consumer.connect();
  await consumer.subscribe({ topic: "stream_topic", fromBeginning: true });

  await consumer.run({
    eachMessage: async ({ message }) => {
      console.log("Received:", message.value.toString());
    },
  });
}

startConsumer();
```

---

## **8. Deployment**

### **Docker (Containerized Deployment)**

- Add a **Dockerfile** for each service
- Use **docker-compose.yml** to manage services

### **AWS Deployment**

- **EC2 Instance** → Host backend & Kafka
- **S3 + CloudFront** → Host frontend
- **Lambda (Optional)** → Serverless event handling

---

## **9. Future Enhancements**

- Implement **GraphQL with Hasura** for better data querying
- Add **Redis** for caching frequently requested data
- Enhance **security** with JWT authentication

---

## **10. Conclusion**

StreamSync is a scalable real-time data streaming app using Kafka, WebSockets, and an ETL pipeline. It ensures fast, reliable data processing and decoupled services.
